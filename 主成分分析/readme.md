

### 降维技术

>场景

* 我们正通过电视观看体育比赛，在电视的显示器上有一个球。
* 显示器大概包含了100万像素点，而球则可能是由较少的像素点组成，例如说一千个像素点。
* 人们实时的将显示器上的百万像素转换成为一个三维图像，该图像就给出运动场上球的位置。
* 在这个过程中，人们已经将百万像素点的数据，降至为三维。这个过程就称为降维(dimensionality reduction)

>数据显示 并非大规模特征下的唯一难题，对数据进行简化还有如下一系列的原因：

* 使得数据集更容易使用
* 降低很多算法的计算开销
* 去除噪音
* 使得结果易懂

>适用范围:

* 在已标注与未标注的数据上都有降维技术。
* 这里我们将主要关注未标注数据上的降维技术，将技术同样也可以应用于已标注的数据。

>在以下3种降维技术中， PCA的应用目前最为广泛，因此本章主要关注PCA。

* 主成分分析(Principal Component Analysis, PCA)
  * 通俗理解：就是找出一个最主要的特征，然后进行分析。
  * 例如： 考察一个人的智力情况，就直接看数学成绩就行(存在：数学、语文、英语成绩)
  
* 因子分析(Factor Analysis)

  * 通俗理解：将多个实测变量转换为少数几个综合指标。它反映一种降维的思想，通过降维将相关性高的变量聚在一起,从而减少需要分析的变量的数量,而减少问题分析的复杂性
  * 例如： 考察一个人的整体情况，就直接组合3样成绩(隐变量)，看平均成绩就行(存在：数学、语文、英语成绩)
  * 应用的领域：社会科学、金融和其他领域
  * 在因子分析中，我们
     * 假设观察数据的成分中有一些观察不到的隐变量(latent variable)。
     * 假设观察数据是这些隐变量和某些噪音的线性组合。
     * 那么隐变量的数据可能比观察数据的数目少，也就说通过找到隐变量就可以实现数据的降维。
  * 独立成分分析(Independ Component Analysis, ICA)
     * 通俗理解：ICA 认为观测信号是若干个独立信号的线性组合，ICA 要做的是一个解混过程。
     * 例如：我们去ktv唱歌，想辨别唱的是什么歌曲？ICA 是观察发现是原唱唱的一首歌【2个独立的声音（原唱／主唱）】。
     * ICA 是假设数据是从 N 个数据源混合组成的，这一点和因子分析有些类似，这些数据源之间在统计上是相互独立的，而在 PCA 中只假设数据是不 相关（线性关系）的。
     * 同因子分析一样，如果数据源的数目少于观察数据的数目，则可以实现降维过程。
     
## PCA

#### PCA 概述

主成分分析(Principal Component Analysis, PCA)：通俗理解：就是找出一个最主要的特征，然后进行分析。

#### PCA 场景

例如： 考察一个人的智力情况，就直接看数学成绩就行(存在：数学、语文、英语成绩)

#### PCA 原理

PCA 工作原理

1,找出第一个主成分的方向，也就是数据 方差最大 的方向。
2,找出第二个主成分的方向，也就是数据 方差次大 的方向，并且该方向与第一个主成分方向 正交(orthogonal 如果是二维空间就叫垂直)。
3,通过这种方式计算出所有的主成分方向。
4,通过数据集的协方差矩阵及其特征值分析，我们就可以得到这些主成分的值。
5,一旦得到了协方差矩阵的特征值和特征向量，我们就可以保留最大的 N 个特征。这些特征向量也给出了 N 个最重要特征的真实结构，我们就可以通过将数据乘上这 N 个特征向量 从而将它转换到新的空间上。

### 为什么正交？

 * 正交是为了数据有效性损失最小
 * 正交的一个原因是特征值的特征向量是正交的

![Image text](https://github.com/moveondo/python-MachineLearning/blob/master/%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90/image/1.jpg)


PCA算法流程

 算法输入：数据集Xmxn
 
* 按列计算数据集X的均值Xmean，然后令Xnew=X−Xmean； 
* 求解矩阵Xnew的协方差矩阵，并将其记为Cov； 
* 计算协方差矩阵COv的特征值和相应的特征向量； 
* 将特征值按照从大到小的排序，选择其中最大的kk个，然后将其对应的kk个特征向量分别作为列向量组成特征向量矩阵Wnxk; 
* 计算XnewWXnewW，即将数据集Xnew投影到选取的特征向量上，这样就得到了我们需要的已经降维的数据集XnewW。




### PCA 优缺点

```
优点：降低数据的复杂性，识别最重要的多个特征。
缺点：不一定需要，且可能损失有用信息。
适用数据类型：数值型数据。

```

### 要点

 * 降维技术使得数据变的更易使用，并且它们往往能够去除数据中的噪音，使得其他机器学习任务更加精确。
 * 降维往往作为预处理步骤，在数据应用到其他算法之前清洗数据。
 * 比较流行的降维技术： 独立成分分析、因子分析 和 主成分分析， 其中又以主成分分析应用最广泛。

 * 本章中的PCA将所有的数据集都调入了内存，如果无法做到，就需要其他的方法来寻找其特征值。
 * 如果使用在线PCA分析的方法，你可以参考一篇优秀的论文 "Incremental Eigenanalysis for Classification"。 
