
### Apriori 算法进行关联分析

> 重要公理:如果一个项目集 S 是频繁的(项目集 S 的出现频度大于最小支持度 s)，那么 S 的任意子集也是频繁的。


### 关联分析

关联分析是一种在大规模数据集中寻找有趣关系的任务。 这些关系可以有两种形式:

* 频繁项集（frequent item sets）: 经常出现在一块的物品的集合。
* 关联规则（associational rules）: 暗示两种物品之间可能存在很强的关系。


#### 频繁 的定义是什么呢？怎么样才算频繁呢？ 

度量它们的方法有很多种，这里我们来简单的介绍下支持度和可信度。

![Image text](https://github.com/moveondo/python-MachineLearning/blob/master/%E8%B4%9D%E5%8F%B6%E6%96%AF/image/native.jpg)


支持度: 数据集中包含该项集的记录所占的比例。例如上图中，{豆奶} 的支持度为 4/5。{豆奶, 尿布} 的支持度为 3/5。

可信度: 针对一条诸如 {尿布} -> {葡萄酒} 这样具体的关联规则来定义的。这条规则的 可信度 被定义为 支持度({尿布, 葡萄酒})/支持度({尿布})，从图中可以看出 支持度({尿布, 葡萄酒}) = 3/5，支持度({尿布}) = 4/5，
所以 {尿布} -> {葡萄酒} 的可信度 = 3/5 / 4/5 = 3/4 = 0.75。

支持度 和 可信度 是用来量化 关联分析 是否成功的一个方法。 假设想找到支持度大于 0.8 的所有项集，应该如何去做呢？ 一个办法是生成一个物品所有可能组合的清单，然后对每一种组合统计它出现的频繁程度，但是当物品成千上万时，上述做法就非常非常慢了。 
我们需要详细分析下这种情况并讨论下 Apriori 原理，该原理会减少关联规则学习时所需的计算量。


### Apriori 原理


如果我们计算{0,1,2,3}所有组合的支持度，也需要计算 15 次。即 2^N - 1 = 2^4 - 1 = 15。

随着物品的增加，计算的次数呈指数的形式增长 ...

为了降低计算次数和时间，研究人员发现了一种所谓的 Apriori 原理，即某个项集是频繁的，那么它的所有子集也是频繁的。 
例如，如果 {0, 1} 是频繁的，那么 {0}, {1} 也是频繁的。
该原理直观上没有什么帮助，但是如果反过来看就有用了，也就是说如果一个项集是 非频繁项集，那么它的所有超集也是非频繁项集，




#### Apriori 算法优缺点

* 优点：易编码实现
* 缺点：在大数据集上可能较慢
* 适用数据类型：数值型 或者 标称型数据。

#### Apriori 算法流程步骤：

* 收集数据：使用任意方法。
* 准备数据：任何数据类型都可以，因为我们只保存集合。
* 分析数据：使用任意方法。
* 训练数据：使用Apiori算法来找到频繁项集。
* 测试算法：不需要测试过程。
* 使用算法：用于发现频繁项集以及物品之间的关联规则。


### Apriori 算法的使用

前面提到，关联分析的目标包括两项: 发现 频繁项集 和发现 关联规则。 首先需要找到 频繁项集，然后才能发现 关联规则。
Apriori 算法是发现 频繁项集 的一种方法。 Apriori 算法的两个输入参数分别是最小支持度和数据集。 该算法首先会生成所有单个物品的项集列表。
接着扫描交易记录来查看哪些项集满足最小支持度要求，那些不满足最小支持度要求的集合会被去掉。 燃尽后对生下来的集合进行组合以声场包含两个元素的项集。
接下来再重新扫描交易记录，去掉不满足最小支持度的项集。 该过程重复进行直到所有项集被去掉


### 生成候选项集

下面会创建一个用于构建初始集合的函数，也会创建一个通过扫描数据集以寻找交易记录子集的函数， 数据扫描的伪代码如下:

* 对数据集中的每条交易记录 tran
* 对每个候选项集 can
  * 检查一下 can 是否是 tran 的子集: 如果是则增加 can 的计数值
* 对每个候选项集
  * 如果其支持度不低于最小值，则保留该项集
  * 返回所有频繁项集列表 以下是一些辅助函数。

两道试题：

  
  
![Image text](https://github.com/moveondo/python-MachineLearning/blob/master/%E8%B4%9D%E5%8F%B6%E6%96%AF/image/native.jpg)

